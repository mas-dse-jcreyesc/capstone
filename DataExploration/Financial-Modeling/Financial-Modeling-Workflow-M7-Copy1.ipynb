{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/notebooks/DataExploration/Financial-Modeling'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2017\n",
    "uri = \"mongodb://mongo/tweets\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# database\n",
    "db = client['irs990']\n",
    "\n",
    "# collection\n",
    "dbYear = db['%s' % year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the columns used for financial clustering\n",
    "with open('../columns.csv') as fin_columns_csv:\n",
    "    fin_columns = fin_columns_csv.read().split(',\\n')\n",
    "\n",
    "# transform columns into dictionary for mongo cursor query\n",
    "find_fin_cols = {}\n",
    "for column_name in fin_columns:\n",
    "    find_fin_cols[column_name] = 1\n",
    "    \n",
    "#execute query against all columns\n",
    "cursor = dbYear.find({},find_fin_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.DataFrame(list(cursor))\n",
    "\n",
    "# for each column, rename without /IRS990/ in the front\n",
    "clean_cols = {}\n",
    "for col in fin_columns:\n",
    "    if col.startswith('/IRS990EZ/'):\n",
    "        clean_cols[col] = col.replace('/IRS990EZ/','')\n",
    "    elif col.startswith('/IRS990'):\n",
    "        clean_cols[col] = col.replace('/IRS990/','')\n",
    "    else:\n",
    "        clean_cols[col] = col\n",
    "        \n",
    "df_original = df_original.rename(columns=clean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read, clean, and separate data by form type.\n",
    "'''\n",
    "# df_original = pd.read_csv('../../capstone-data/sample_data_2017_M4_v3.csv', \n",
    "#                  dtype= {'FormationYr':'object'},\n",
    "#                  low_memory=False)\n",
    "# df_original = df_original.drop(['ActivityOrMissionDesc'\n",
    "#               , 'BooksInCareOfDetail/USAddress/ZIPCode'\n",
    "#               , 'PrincipalOfficerNm'\n",
    "#               , 'Desc'\n",
    "#               , 'MissionDesc'\n",
    "#               , 'PrimaryExemptPurposeTxt'\n",
    "#               , 'OrganizationName'\n",
    "#               , 'URL'\n",
    "#               , 'WebsiteAddressTxt'\n",
    "#               , '_id'\n",
    "#               , 'EmployeeCnt' # dupe of TotalEmployeeCnt\n",
    "#               , 'NetAssetsOrFundBalancesEOYAmt' #dupe of TotalNetAssetsFundBalanceGrp/EOYAmt (990) and NetAssetsFundBalanceGrp/EOYAmt (EZ)\n",
    "# #               , 'TaxExemptBondsInd'\n",
    "# #               , 'TotLiabNetAssetsFundBalanceGrp/EOYAmt' # sum of TotalLiabilitiesGrp/EOYAmt and TotalNetAssetsFundBalanceGrp/EOYAmt\n",
    "#               , 'TotalAssetsGrp/EOYAmt' # dupe of TotLiabNetAssetsFundBalanceGrp/EOYAmt\n",
    "#               , 'TotalAssetsGrp/BOYAmt'\n",
    "#               , 'NoListedPersonsCompensatedInd'\n",
    "#               , 'TaxPeriod'\n",
    "#              ], axis =1)\n",
    "\n",
    "df_990 = df_original[df_original['FormType'] == '990']\n",
    "df_990 = df_990.drop(['FormType'], axis = 1)\n",
    "df_990 = df_990.dropna(how = \"all\", axis = 1)\n",
    "df_990 = df_990.fillna(0)\n",
    "df_990.reset_index(inplace=True, drop = True)\n",
    "\n",
    "df_990EZ = df_original[df_original['FormType'] == '990EZ']\n",
    "df_990EZ = df_990EZ.drop(['FormType'], axis = 1)\n",
    "df_990EZ = df_990EZ.dropna(how = \"all\", axis = 1)\n",
    "df_990EZ = df_990EZ.fillna(0)\n",
    "df_990EZ.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form 990 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b, **eval_kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m   1528\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_arith_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mmasked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m   1008\u001b[0m                 result[mask] = op(xrav[mask],\n\u001b[0;32m-> 1009\u001b[0;31m                                   com.values_from_object(yrav[mask]))\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5fad63f5398c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# TotalContributionsAmt divided by RevenueAmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mdf_990\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotalContribRatio'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_990\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotalContributionsAmt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdf_990\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RevenueAmt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mdf_990\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotalContribRatio'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace_infinity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_990\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotalContribRatio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m   1581\u001b[0m             \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_na_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m         return construct_result(left, result,\n\u001b[1;32m   1585\u001b[0m                                 index=left.index, name=res_name, dtype=None)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m                 return libalgos.arrmap_object(lvalues,\n\u001b[0;32m-> 1533\u001b[0;31m                                               lambda x: op(x, rvalues))\n\u001b[0m\u001b[1;32m   1534\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/algos.pyx\u001b[0m in \u001b[0;36mpandas._libs.algos.arrmap\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m                 return libalgos.arrmap_object(lvalues,\n\u001b[0;32m-> 1533\u001b[0;31m                                               lambda x: op(x, rvalues))\n\u001b[0m\u001b[1;32m   1534\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data prep & feature engineering\n",
    "'''\n",
    "\n",
    "# Functions for cleaning\n",
    "def replace_infinity(result):\n",
    "    result = result.fillna(0)\n",
    "    result = result.replace(np.inf, 1.0)\n",
    "    result = result.replace(-np.inf, 0.0)\n",
    "    return result\n",
    "\n",
    "def calculatePercentChange(series1, series2):\n",
    "    result = (series1-series2)/series1\n",
    "    return replace_infinity(result)\n",
    "\n",
    "def scaleColumns(df, cols_to_scale, scaler):\n",
    "    for col in cols_to_scale:\n",
    "        df[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(df[col])),columns=[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Transform required boolean columns to binary\n",
    "df_990['ScheduleBRequiredInd'] = df_990['ScheduleBRequiredInd'].replace('false', 0).replace('true', 1).replace('0', 0).replace('1', 1).astype('int64')\n",
    "df_990['TaxExemptBondsInd'] = df_990['TaxExemptBondsInd'].replace('false', 0).replace('true', 1).replace('0', 0).replace('1', 1).astype('int64')\n",
    "\n",
    "# Related Org binary\n",
    "df_990['RelatedOrg'] = df_990['RelatedOrganizationsAmt'].apply(lambda row: 1 if row != 0 else row)\n",
    "\n",
    "# Transform formation year into age calcualtion\n",
    "df_990['FormationYr'] = df_990['FormationYr'].astype('int64')\n",
    "now = datetime.now()\n",
    "\n",
    "# Age is current year minus formation year, else 0\n",
    "df_990['FilerAge'] = df_990['FormationYr'].apply(lambda x: now.year-x if x != 0 else 0)\n",
    "\n",
    "# TotalContributionsAmt divided by RevenueAmt\n",
    "df_990['TotalContribRatio'] = df_990['TotalContributionsAmt']/df_990['RevenueAmt']\n",
    "df_990['TotalContribRatio'] = replace_infinity(df_990['TotalContribRatio'])\n",
    "\n",
    "# ProgramServicesAmt divided by TotalAmt\n",
    "df_990['ProgramServicesRatio'] = df_990['TotalFunctionalExpensesGrp/ProgramServicesAmt']/df_990['TotalFunctionalExpensesGrp/TotalAmt']\n",
    "df_990['ProgramServicesRatio'] = replace_infinity(df_990['ProgramServicesRatio'])\n",
    "\n",
    "# ManagementAndGeneralAmt divided by TotalAmt\n",
    "df_990['ManagementExpRatio'] = df_990['TotalFunctionalExpensesGrp/ManagementAndGeneralAmt']/df_990['TotalFunctionalExpensesGrp/TotalAmt']\n",
    "df_990['ManagementExpRatio'] = replace_infinity(df_990['ManagementExpRatio'])\n",
    "\n",
    "# FundraisingAmt divided by TotalAmt\n",
    "df_990['FundraisingRatio'] = df_990['TotalFunctionalExpensesGrp/FundraisingAmt']/df_990['TotalFunctionalExpensesGrp/TotalAmt']\n",
    "df_990['FundraisingRatio'] = replace_infinity(df_990['FundraisingRatio'])\n",
    "\n",
    "# % Change of Assets over the year\n",
    "# df_990['PercentTotalAsstChng'] = calculatePercentChange(df_990['TotalAssetsGrp/BOYAmt'], df_990['TotalAssetsGrp/EOYAmt'])\n",
    "df_990['PercentFundBalChng'] = calculatePercentChange(df_990['TotLiabNetAssetsFundBalanceGrp/BOYAmt']-df_990['TotalLiabilitiesGrp/BOYAmt'], df_990['TotLiabNetAssetsFundBalanceGrp/EOYAmt']-df_990['TotalLiabilitiesGrp/EOYAmt'])\n",
    "df_990['PercentTotalLiabChng'] = calculatePercentChange(df_990['TotalLiabilitiesGrp/BOYAmt'], df_990['TotalLiabilitiesGrp/EOYAmt'])\n",
    "\n",
    "# % Change Previous Year to Current Year\n",
    "df_990['PercentSalaryChng'] = calculatePercentChange(df_990['PYSalariesCompEmpBnftPaidAmt'], df_990['CYSalariesCompEmpBnftPaidAmt'])\n",
    "df_990['PercentTotalExpenseChng'] = calculatePercentChange(df_990['PYTotalExpensesAmt'], df_990['CYTotalExpensesAmt'])\n",
    "df_990['PercentProfFndrsngExpnsChng'] = calculatePercentChange(df_990['PYTotalProfFndrsngExpnsAmt'], df_990['CYTotalProfFndrsngExpnsAmt'])\n",
    "df_990['PercentRevenueChng'] = calculatePercentChange(df_990['PYTotalRevenueAmt'], df_990['CYTotalRevenueAmt'])\n",
    "\n",
    "# Drop Columnsn\n",
    "df_990 = df_990.drop(columns=['FormationYr',\n",
    "                      'TotalContributionsAmt',\n",
    "                      'TotalFunctionalExpensesGrp/ProgramServicesAmt',\n",
    "                      'TotalFunctionalExpensesGrp/ManagementAndGeneralAmt',\n",
    "                      'TotalFunctionalExpensesGrp/FundraisingAmt',\n",
    "#                       'TotalAssetsGrp/BOYAmt',\n",
    "                      'TotLiabNetAssetsFundBalanceGrp/BOYAmt',\n",
    "                      'TotLiabNetAssetsFundBalanceGrp/EOYAmt',\n",
    "                      'TotalLiabilitiesGrp/BOYAmt',\n",
    "                      'RelatedOrganizationsAmt',\n",
    "                      'CYSalariesCompEmpBnftPaidAmt',\n",
    "                      'CYTotalExpensesAmt',\n",
    "                      'CYTotalProfFndrsngExpnsAmt',\n",
    "                      'CYTotalRevenueAmt',\n",
    "                      'PYSalariesCompEmpBnftPaidAmt',\n",
    "                      'PYTotalExpensesAmt',\n",
    "                      'PYTotalProfFndrsngExpnsAmt',\n",
    "                      'PYTotalRevenueAmt'      \n",
    "                     ])\n",
    "\n",
    "# Scale columns where it makes sense to\n",
    "cols = df_990.columns\n",
    "set_cols = set(cols)\n",
    "cols_not_scale = ['EIN', \n",
    "                  'FilerAge',\n",
    "                  'TotalContribRatio',\n",
    "                  'ProgramServicesRatio',\n",
    "                  'FundraisingRatio',\n",
    "                  'ManagementExpRatio',\n",
    "                  'PercentFundBalChng',\n",
    "#                   'PercentTotalAsstChng',\n",
    "                  'PercentTotalLiabChng',\n",
    "                  'PercentSalaryChng',\n",
    "                  'PercentTotalExpenseChng',\n",
    "                  'PercentProfFndrsngExpnsChng',\n",
    "                  'PercentRevenueChng',\n",
    "                  'RelatedOrg',\n",
    "                  'ScheduleBRequiredInd',\n",
    "                  'TaxExemptBondsInd'\n",
    "                 ]\n",
    "\n",
    "for col in cols_not_scale:\n",
    "    set_cols.remove(col)\n",
    "    \n",
    "scaler = preprocessing.StandardScaler()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "df_990 = scaleColumns(df_990, list(set_cols), min_max_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dimensionality reduction with PCA\n",
    "'''\n",
    "\n",
    "# Helper functions\n",
    "def PCA_components(df):\n",
    "    pca = PCA()\n",
    "    pca.fit(df.loc[:, df.columns != 'EIN'])\n",
    "    df_pca = pca.transform(df.loc[:, df.columns != 'EIN'])\n",
    "    var = pca.explained_variance_ratio_\n",
    "    var_cumsum = np.cumsum(var)\n",
    "    comp = range(1, len(var)+1)\n",
    "\n",
    "    %matplotlib inline\n",
    "    plt.plot(comp,var_cumsum)\n",
    "    plt.xlabel('Components')\n",
    "    plt.ylabel('% Variance')\n",
    "    plt.title('Variance explained by each component')\n",
    "    print(var_cumsum)\n",
    "\n",
    "def fit_pca(df, n):\n",
    "    eins = list(df['EIN'])\n",
    "    pca = PCA(n_components = n)\n",
    "    pca.fit(df.loc[:, df.columns != 'EIN'])\n",
    "    df_pca = pca.transform(df.loc[:, df.columns != 'EIN'])\n",
    "    df_pca = pd.DataFrame(df_pca)\n",
    "    df_pca['EIN'] = eins\n",
    "    return df_pca\n",
    "\n",
    "PCA_components(df_990)\n",
    "df_990_reduced = fit_pca(df_990, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hierarchical clustering using clustering.py script\n",
    "'''\n",
    "X = df_990_reduced.loc[:, df_990_reduced.columns != 'EIN'].values\n",
    "\n",
    "'''\n",
    "Z is linkage matrix\n",
    "gap_metrics is dictionary of ks, logWs, logBWs, and stderr values\n",
    "bc is best number of clusters\n",
    "clusters are labels\n",
    "'''\n",
    "Z, gap_metrics, bc, clusters_990 = clustering.create_clusters(X, C = 500)\n",
    "\n",
    "df_990['labels'] = clusters_990\n",
    "# df_990.groupby(['labels']).count()['EIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form 990EZ Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data prep & feature engineering\n",
    "'''\n",
    "\n",
    "# Calculate Total Liabilities column\n",
    "df_990EZ['TotalLiabilitiesGrp/EOYAmt'] = df_990EZ['Form990TotalAssetsGrp/EOYAmt'] - df_990EZ['NetAssetsOrFundBalancesGrp/EOYAmt']\n",
    "df_990EZ = df_990EZ.drop(columns=['Form990TotalAssetsGrp/EOYAmt'])\n",
    "\n",
    "# Scale columns where it makes sense to\n",
    "cols = df_990EZ.columns\n",
    "set_cols = set(cols)\n",
    "cols_not_scale = ['EIN']\n",
    "\n",
    "for col in cols_not_scale:\n",
    "    set_cols.remove(col)\n",
    "    \n",
    "scaler = preprocessing.StandardScaler()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "df_990EZ = scaleColumns(df_990EZ, list(set_cols), min_max_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hierarchical clustering using clustering.py script\n",
    "'''\n",
    "X = df_990EZ.loc[:, df_990EZ.columns != 'EIN'].values\n",
    "\n",
    "'''\n",
    "Z is linkage matrix\n",
    "gap_metrics is dictionary of ks, logWs, logBWs, and stderr values\n",
    "bc is best number of clusters\n",
    "clusters are labels\n",
    "'''\n",
    "Z, gap_metrics, bc, clusters_990EZ = clustering.create_clusters(X, C = 500)\n",
    "\n",
    "df_990EZ['labels'] = clusters_990EZ\n",
    "# df_990EZ.groupby(['labels']).count()['EIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge cluster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combine original data sets and re-scale\n",
    "'''\n",
    "\n",
    "df_all = df_original[['EIN', 'GrossReceiptsAmt']]\n",
    "df_all = df_all.fillna(0)\n",
    "df_all = scaleColumns(df_all, ['GrossReceiptsAmt'], min_max_scaler)\n",
    "df_all = df_all.merge(df_990[['EIN', 'labels']], how = 'left', on = 'EIN')\n",
    "df_all = df_all.merge(df_990EZ[['EIN', 'labels']], how = 'left', on = 'EIN')\n",
    "df_all = df_all.rename(index=str, columns = {'labels_x': 'labels_990', 'labels_y': 'labels_EZ'})\n",
    "\n",
    "\n",
    "'''\n",
    "Find the means of GrossReceiptAmt for each cluster\n",
    "'''\n",
    "means990 = df_all[~df_all['labels_990'].isna()]\n",
    "means990 = pd.DataFrame(means990.groupby(['labels_990']).mean()['GrossReceiptsAmt'])\n",
    "means990.reset_index(inplace = True)\n",
    "x990 = means990.values\n",
    "\n",
    "meansEZ = df_all[~df_all['labels_EZ'].isna()]\n",
    "meansEZ = pd.DataFrame(meansEZ.groupby(['labels_EZ']).mean()['GrossReceiptsAmt'])\n",
    "meansEZ.reset_index(inplace = True)\n",
    "xEZ = meansEZ.values\n",
    "\n",
    "\n",
    "'''\n",
    "Calculate similarity scores based on cluster means \n",
    "1 row per EZ cluster, 1 col per 990 cluster\n",
    "'''\n",
    "similarity_scores = euclidean_distances(xEZ[:,1:], x990[:,1:])\n",
    "\n",
    "\n",
    "'''\n",
    "Creates column for the min sim score (i.e. closest match) and position of closest cluster\n",
    "'''\n",
    "min_distance = []\n",
    "position = []\n",
    "for row in similarity_scores:\n",
    "    min_distance.append(min(row))\n",
    "    position.append(min(enumerate(row),key=lambda x: x[1])[0])\n",
    "\n",
    "meansEZ['min_distance'] = min_distance\n",
    "meansEZ['position'] = position\n",
    "\n",
    "\n",
    "'''\n",
    "Bring in means990 data for closest cluster\n",
    "'''\n",
    "combined_clusters = meansEZ.merge(means990, how = 'left', left_on = 'position', right_index = True)\n",
    "combined_clusters = combined_clusters.rename(index=str, columns = {'GrossReceiptsAmt_y': 'GrossReceiptsAmt_990', 'GrossReceiptsAmt_x': 'GrossReceiptsAmt_EZ'})\n",
    "\n",
    "\n",
    "'''\n",
    "If min distance < threshold, merge clusters, otherwise keep create new cluster\n",
    "'''\n",
    "threshold = .000001\n",
    "new_cluster_id = max(df_990['labels'])\n",
    "final_labels = []\n",
    "for i in combined_clusters.index:\n",
    "    if combined_clusters.loc[i, 'min_distance'] < threshold:\n",
    "        final_labels.append(combined_clusters.loc[i, 'labels_990'])\n",
    "    else:\n",
    "        new_cluster_id += 1\n",
    "        final_labels.append(new_cluster_id)\n",
    "combined_clusters['final_labels'] = [int(x) for x in final_labels]\n",
    "combined_clusters['labels_EZ'] = combined_clusters['labels_EZ'].astype('int64')\n",
    "\n",
    "\n",
    "'''\n",
    "Add final_label to df_990EZ dataframe\n",
    "'''\n",
    "df_990EZ = df_990EZ.merge(combined_clusters[['labels_EZ', 'final_labels']], how = 'left', left_on = 'labels', right_on = 'labels_EZ')\n",
    "df_990EZ = df_990EZ.drop(['labels', 'labels_EZ'], axis = 1)\n",
    "df_990EZ = df_990EZ.rename(index = str, columns = {'final_labels': 'labels'})\n",
    "\n",
    "'''\n",
    "Final dataframe with labels\n",
    "'''\n",
    "df_original = df_original.merge(df_990[['EIN', 'labels']], how = 'left', on = 'EIN')\n",
    "df_original = df_original.merge(df_990EZ[['EIN', 'labels']], how = 'left', on = 'EIN')\n",
    "df_original['labels'] = df_original['labels_x'].combine_first(df_original['labels_y'])\n",
    "df_original = df_original.drop(['labels_x', 'labels_y'], axis = 1)\n",
    "df_original['labels'] = df_original['labels'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_original.to_csv('./labels_M7.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaleColumns(df, cols_to_scale, scaler):\n",
    "#     for col in cols_to_scale:\n",
    "#         df[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(df[col])),columns=[col])\n",
    "#     return df\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data for variance visualization (Tableau)\n",
    "'''\n",
    "\n",
    "# df_original = pd.read_csv('./labels_M7.csv', dtype = {'FormType': 'object'})\n",
    "df_final_990 = df_original[df_original['FormType'] == '990']\n",
    "df_final_990 = df_final_990[['EIN', 'GrossReceiptsAmt', 'RevenueAmt', 'TotalNetAssetsFundBalanceGrp/EOYAmt', 'TotalLiabilitiesGrp/EOYAmt', 'labels']]\n",
    "df_final_990.columns = ['EIN', 'Gross Receipts', 'Revenue', 'Fund Balance', 'Liabilities', 'labels']\n",
    "\n",
    "df_final_990EZ = df_original[df_original['FormType'] == '990EZ']\n",
    "df_final_990EZ['TotalLiabilitiesGrp/EOYAmt'] = df_final_990EZ['Form990TotalAssetsGrp/EOYAmt'] - df_final_990EZ['NetAssetsOrFundBalancesGrp/EOYAmt']\n",
    "df_final_990EZ = df_final_990EZ[['EIN', 'GrossReceiptsAmt', 'TotalRevenueAmt', 'NetAssetsOrFundBalancesGrp/EOYAmt', 'TotalLiabilitiesGrp/EOYAmt', 'labels']]\n",
    "df_final_990EZ.columns = ['EIN', 'Gross Receipts', 'Revenue', 'Fund Balance', 'Liabilities', 'labels']\n",
    "\n",
    "df_final = df_final_990.append(df_final_990EZ)\n",
    "df_final = df_final.fillna(0)\n",
    "\n",
    "cols = list(df_final.columns)[1:-1]\n",
    "df_final = scaleColumns(df_final, cols, min_max_scaler)\n",
    "# df_final.to_csv('./var_viz_M7.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate distance from cluster center for each org.\n",
    "'''\n",
    "\n",
    "cluster_means = pd.DataFrame(df_final.groupby(['labels']).mean()).reset_index()\n",
    "cluster_means.drop(['EIN'], inplace=True, axis = 1)\n",
    "cluster_means = cluster_means.values\n",
    "\n",
    "clusters = set(df_final['labels'])\n",
    "names = [\"distance_\" + str(cluster) for cluster in clusters]\n",
    "\n",
    "'''\n",
    "Try Euclidean, cosine, and Mahalanobis\n",
    "'''\n",
    "\n",
    "for i, row in enumerate(df_final.values):\n",
    "    for means in cluster_means:\n",
    "        for cluster in clusters:\n",
    "            if means[0] == cluster: # check for same cluster label\n",
    "                x = row[1:-1].reshape([1,4])\n",
    "                y = means[1:].reshape([1,4])\n",
    "                df_final.loc[i, names[cluster-1]] = (float(cosine_similarity(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.to_csv('./df_final_M7.csv', index = False)\n",
    "# df_final.to_csv('./df_final_M8_cosine2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: save to db\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
