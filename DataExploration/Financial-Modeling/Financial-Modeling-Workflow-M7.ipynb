{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read, clean, and separate data by form type.\n",
    "'''\n",
    "df_original = pd.read_csv('../../../capstone-data/sample_data_2017_M4_v3.csv', \n",
    "                 dtype= {'FormationYr':'object'},\n",
    "                 low_memory=False)\n",
    "df_original = df_original.drop(['ActivityOrMissionDesc'\n",
    "              , 'BooksInCareOfDetail/USAddress/ZIPCode'\n",
    "              , 'PrincipalOfficerNm'\n",
    "              , 'Desc'\n",
    "              , 'MissionDesc'\n",
    "              , 'PrimaryExemptPurposeTxt'\n",
    "              , 'OrganizationName'\n",
    "              , 'URL'\n",
    "              , 'WebsiteAddressTxt'\n",
    "              , '_id'\n",
    "              , 'EmployeeCnt' # dupe of TotalEmployeeCnt\n",
    "              , 'NetAssetsOrFundBalancesEOYAmt' #dupe of TotalNetAssetsFundBalanceGrp/EOYAmt (990) and NetAssetsFundBalanceGrp/EOYAmt (EZ)\n",
    "#               , 'TaxExemptBondsInd'\n",
    "#               , 'TotLiabNetAssetsFundBalanceGrp/EOYAmt' # sum of TotalLiabilitiesGrp/EOYAmt and TotalNetAssetsFundBalanceGrp/EOYAmt\n",
    "              , 'TotalAssetsGrp/EOYAmt' # dupe of TotLiabNetAssetsFundBalanceGrp/EOYAmt\n",
    "              , 'TotalAssetsGrp/BOYAmt'\n",
    "              , 'NoListedPersonsCompensatedInd'\n",
    "              , 'TaxPeriod'\n",
    "             ], axis =1)\n",
    "\n",
    "df_990 = df_original[df_original['FormType'] == '990']\n",
    "df_990 = df_990.drop(['FormType'], axis = 1)\n",
    "df_990 = df_990.dropna(how = \"all\", axis = 1)\n",
    "df_990 = df_990.fillna(0)\n",
    "df_990.reset_index(inplace=True, drop = True)\n",
    "\n",
    "df_990EZ = df_original[df_original['FormType'] == '990EZ']\n",
    "df_990EZ = df_990EZ.drop(['FormType'], axis = 1)\n",
    "df_990EZ = df_990EZ.dropna(how = \"all\", axis = 1)\n",
    "df_990EZ = df_990EZ.fillna(0)\n",
    "df_990EZ.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form 990 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data prep & feature engineering\n",
    "'''\n",
    "\n",
    "# Functions for cleaning\n",
    "def replace_infinity(result):\n",
    "    result = result.fillna(0)\n",
    "    result = result.replace(np.inf, 1.0)\n",
    "    result = result.replace(-np.inf, 0.0)\n",
    "    return result\n",
    "\n",
    "def calculatePercentChange(series1, series2):\n",
    "    result = (series1-series2)/series1\n",
    "    return replace_infinity(result)\n",
    "\n",
    "def scaleColumns(df, cols_to_scale, scaler):\n",
    "    for col in cols_to_scale:\n",
    "        df[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(df[col])),columns=[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Transform required boolean columns to binary\n",
    "df_990['ScheduleBRequiredInd'] = df_990['ScheduleBRequiredInd'].replace('false', 0).replace('true', 1).replace('0', 0).replace('1', 1).astype('int64')\n",
    "df_990['TaxExemptBondsInd'] = df_990['TaxExemptBondsInd'].replace('false', 0).replace('true', 1).replace('0', 0).replace('1', 1).astype('int64')\n",
    "\n",
    "# Related Org binary\n",
    "df_990['RelatedOrg'] = df_990['RelatedOrganizationsAmt'].apply(lambda row: 1 if row != 0 else row)\n",
    "\n",
    "# Transform formation year into age calcualtion\n",
    "df_990['FormationYr'] = df_990['FormationYr'].astype('int64')\n",
    "now = datetime.now()\n",
    "\n",
    "# Age is current year minus formation year, else 0\n",
    "df_990['FilerAge'] = df_990['FormationYr'].apply(lambda x: now.year-x if x != 0 else 0)\n",
    "\n",
    "# TotalContributionsAmt divided by RevenueAmt\n",
    "df_990['TotalContribRatio'] = df_990['TotalContributionsAmt']/df_990['RevenueAmt']\n",
    "df_990['TotalContribRatio'] = replace_infinity(df_990['TotalContribRatio'])\n",
    "\n",
    "# ProgramServicesAmt divided by TotalAmt\n",
    "df_990['ProgramServicesRatio'] = df_990['TotalFunctionalExpensesGrp/ProgramServicesAmt']/df_990['TotalFunctionalExpensesGrp/TotalAmt']\n",
    "df_990['ProgramServicesRatio'] = replace_infinity(df_990['ProgramServicesRatio'])\n",
    "\n",
    "# ManagementAndGeneralAmt divided by TotalAmt\n",
    "df_990['ManagementExpRatio'] = df_990['TotalFunctionalExpensesGrp/ManagementAndGeneralAmt']/df_990['TotalFunctionalExpensesGrp/TotalAmt']\n",
    "df_990['ManagementExpRatio'] = replace_infinity(df_990['ManagementExpRatio'])\n",
    "\n",
    "# FundraisingAmt divided by TotalAmt\n",
    "df_990['FundraisingRatio'] = df_990['TotalFunctionalExpensesGrp/FundraisingAmt']/df_990['TotalFunctionalExpensesGrp/TotalAmt']\n",
    "df_990['FundraisingRatio'] = replace_infinity(df_990['FundraisingRatio'])\n",
    "\n",
    "# % Change of Assets over the year\n",
    "# df_990['PercentTotalAsstChng'] = calculatePercentChange(df_990['TotalAssetsGrp/BOYAmt'], df_990['TotalAssetsGrp/EOYAmt'])\n",
    "df_990['PercentFundBalChng'] = calculatePercentChange(df_990['TotLiabNetAssetsFundBalanceGrp/BOYAmt']-df_990['TotalLiabilitiesGrp/BOYAmt'], df_990['TotLiabNetAssetsFundBalanceGrp/EOYAmt']-df_990['TotalLiabilitiesGrp/EOYAmt'])\n",
    "df_990['PercentTotalLiabChng'] = calculatePercentChange(df_990['TotalLiabilitiesGrp/BOYAmt'], df_990['TotalLiabilitiesGrp/EOYAmt'])\n",
    "\n",
    "# % Change Previous Year to Current Year\n",
    "df_990['PercentSalaryChng'] = calculatePercentChange(df_990['PYSalariesCompEmpBnftPaidAmt'], df_990['CYSalariesCompEmpBnftPaidAmt'])\n",
    "df_990['PercentTotalExpenseChng'] = calculatePercentChange(df_990['PYTotalExpensesAmt'], df_990['CYTotalExpensesAmt'])\n",
    "df_990['PercentProfFndrsngExpnsChng'] = calculatePercentChange(df_990['PYTotalProfFndrsngExpnsAmt'], df_990['CYTotalProfFndrsngExpnsAmt'])\n",
    "df_990['PercentRevenueChng'] = calculatePercentChange(df_990['PYTotalRevenueAmt'], df_990['CYTotalRevenueAmt'])\n",
    "\n",
    "# Drop Columnsn\n",
    "df_990 = df_990.drop(columns=['FormationYr',\n",
    "                      'TotalContributionsAmt',\n",
    "                      'TotalFunctionalExpensesGrp/ProgramServicesAmt',\n",
    "                      'TotalFunctionalExpensesGrp/ManagementAndGeneralAmt',\n",
    "                      'TotalFunctionalExpensesGrp/FundraisingAmt',\n",
    "#                       'TotalAssetsGrp/BOYAmt',\n",
    "                      'TotLiabNetAssetsFundBalanceGrp/BOYAmt',\n",
    "                      'TotLiabNetAssetsFundBalanceGrp/EOYAmt',\n",
    "                      'TotalLiabilitiesGrp/BOYAmt',\n",
    "                      'RelatedOrganizationsAmt',\n",
    "                      'CYSalariesCompEmpBnftPaidAmt',\n",
    "                      'CYTotalExpensesAmt',\n",
    "                      'CYTotalProfFndrsngExpnsAmt',\n",
    "                      'CYTotalRevenueAmt',\n",
    "                      'PYSalariesCompEmpBnftPaidAmt',\n",
    "                      'PYTotalExpensesAmt',\n",
    "                      'PYTotalProfFndrsngExpnsAmt',\n",
    "                      'PYTotalRevenueAmt'      \n",
    "                     ])\n",
    "\n",
    "# Scale columns where it makes sense to\n",
    "cols = df_990.columns\n",
    "set_cols = set(cols)\n",
    "cols_not_scale = ['EIN', \n",
    "                  'FilerAge',\n",
    "                  'TotalContribRatio',\n",
    "                  'ProgramServicesRatio',\n",
    "                  'FundraisingRatio',\n",
    "                  'ManagementExpRatio',\n",
    "                  'PercentFundBalChng',\n",
    "#                   'PercentTotalAsstChng',\n",
    "                  'PercentTotalLiabChng',\n",
    "                  'PercentSalaryChng',\n",
    "                  'PercentTotalExpenseChng',\n",
    "                  'PercentProfFndrsngExpnsChng',\n",
    "                  'PercentRevenueChng',\n",
    "                  'RelatedOrg',\n",
    "                  'ScheduleBRequiredInd',\n",
    "                  'TaxExemptBondsInd'\n",
    "                 ]\n",
    "\n",
    "for col in cols_not_scale:\n",
    "    set_cols.remove(col)\n",
    "    \n",
    "scaler = preprocessing.StandardScaler()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "df_990 = scaleColumns(df_990, list(set_cols), min_max_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dimensionality reduction with PCA\n",
    "'''\n",
    "\n",
    "# Helper functions\n",
    "def PCA_components(df):\n",
    "    pca = PCA()\n",
    "    pca.fit(df.loc[:, df.columns != 'EIN'])\n",
    "    df_pca = pca.transform(df.loc[:, df.columns != 'EIN'])\n",
    "    var = pca.explained_variance_ratio_\n",
    "    var_cumsum = np.cumsum(var)\n",
    "    comp = range(1, len(var)+1)\n",
    "\n",
    "    %matplotlib inline\n",
    "    plt.plot(comp,var_cumsum)\n",
    "    plt.xlabel('Components')\n",
    "    plt.ylabel('% Variance')\n",
    "    plt.title('Variance explained by each component')\n",
    "    print(var_cumsum)\n",
    "\n",
    "def fit_pca(df, n):\n",
    "    eins = list(df['EIN'])\n",
    "    pca = PCA(n_components = n)\n",
    "    pca.fit(df.loc[:, df.columns != 'EIN'])\n",
    "    df_pca = pca.transform(df.loc[:, df.columns != 'EIN'])\n",
    "    df_pca = pd.DataFrame(df_pca)\n",
    "    df_pca['EIN'] = eins\n",
    "    return df_pca\n",
    "\n",
    "PCA_components(df_990)\n",
    "df_990_reduced = fit_pca(df_990, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hierarchical clustering using clustering.py script\n",
    "'''\n",
    "X = df_990_reduced.loc[:, df_990_reduced.columns != 'EIN'].values\n",
    "\n",
    "'''\n",
    "Z is linkage matrix\n",
    "gap_metrics is dictionary of ks, logWs, logBWs, and stderr values\n",
    "bc is best number of clusters\n",
    "clusters are labels\n",
    "'''\n",
    "Z, gap_metrics, bc, clusters_990 = clustering.create_clusters(X, C = 500)\n",
    "\n",
    "df_990['labels'] = clusters_990\n",
    "# df_990.groupby(['labels']).count()['EIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form 990EZ Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data prep & feature engineering\n",
    "'''\n",
    "\n",
    "# Calculate Total Liabilities column\n",
    "df_990EZ['TotalLiabilitiesGrp/EOYAmt'] = df_990EZ['Form990TotalAssetsGrp/EOYAmt'] - df_990EZ['NetAssetsOrFundBalancesGrp/EOYAmt']\n",
    "df_990EZ = df_990EZ.drop(columns=['Form990TotalAssetsGrp/EOYAmt'])\n",
    "\n",
    "# Scale columns where it makes sense to\n",
    "cols = df_990EZ.columns\n",
    "set_cols = set(cols)\n",
    "cols_not_scale = ['EIN']\n",
    "\n",
    "for col in cols_not_scale:\n",
    "    set_cols.remove(col)\n",
    "    \n",
    "scaler = preprocessing.StandardScaler()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "df_990EZ = scaleColumns(df_990EZ, list(set_cols), min_max_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hierarchical clustering using clustering.py script\n",
    "'''\n",
    "X = df_990EZ.loc[:, df_990EZ.columns != 'EIN'].values\n",
    "\n",
    "'''\n",
    "Z is linkage matrix\n",
    "gap_metrics is dictionary of ks, logWs, logBWs, and stderr values\n",
    "bc is best number of clusters\n",
    "clusters are labels\n",
    "'''\n",
    "Z, gap_metrics, bc, clusters_990EZ = clustering.create_clusters(X, C = 500)\n",
    "\n",
    "df_990EZ['labels'] = clusters_990EZ\n",
    "# df_990EZ.groupby(['labels']).count()['EIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge cluster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combine original data sets and re-scale\n",
    "'''\n",
    "\n",
    "df_all = df_original[['EIN', 'GrossReceiptsAmt']]\n",
    "df_all = df_all.fillna(0)\n",
    "df_all = scaleColumns(df_all, ['GrossReceiptsAmt'], min_max_scaler)\n",
    "df_all = df_all.merge(df_990[['EIN', 'labels']], how = 'left', on = 'EIN')\n",
    "df_all = df_all.merge(df_990EZ[['EIN', 'labels']], how = 'left', on = 'EIN')\n",
    "df_all = df_all.rename(index=str, columns = {'labels_x': 'labels_990', 'labels_y': 'labels_EZ'})\n",
    "\n",
    "\n",
    "'''\n",
    "Find the means of GrossReceiptAmt for each cluster\n",
    "'''\n",
    "means990 = df_all[~df_all['labels_990'].isna()]\n",
    "means990 = pd.DataFrame(means990.groupby(['labels_990']).mean()['GrossReceiptsAmt'])\n",
    "means990.reset_index(inplace = True)\n",
    "x990 = means990.values\n",
    "\n",
    "meansEZ = df_all[~df_all['labels_EZ'].isna()]\n",
    "meansEZ = pd.DataFrame(meansEZ.groupby(['labels_EZ']).mean()['GrossReceiptsAmt'])\n",
    "meansEZ.reset_index(inplace = True)\n",
    "xEZ = meansEZ.values\n",
    "\n",
    "\n",
    "'''\n",
    "Calculate similarity scores based on cluster means \n",
    "1 row per EZ cluster, 1 col per 990 cluster\n",
    "'''\n",
    "similarity_scores = euclidean_distances(xEZ[:,1:], x990[:,1:])\n",
    "\n",
    "\n",
    "'''\n",
    "Creates column for the min sim score (i.e. closest match) and position of closest cluster\n",
    "'''\n",
    "min_distance = []\n",
    "position = []\n",
    "for row in similarity_scores:\n",
    "    min_distance.append(min(row))\n",
    "    position.append(min(enumerate(row),key=lambda x: x[1])[0])\n",
    "\n",
    "meansEZ['min_distance'] = min_distance\n",
    "meansEZ['position'] = position\n",
    "\n",
    "\n",
    "'''\n",
    "Bring in means990 data for closest cluster\n",
    "'''\n",
    "combined_clusters = meansEZ.merge(means990, how = 'left', left_on = 'position', right_index = True)\n",
    "combined_clusters = combined_clusters.rename(index=str, columns = {'GrossReceiptsAmt_y': 'GrossReceiptsAmt_990', 'GrossReceiptsAmt_x': 'GrossReceiptsAmt_EZ'})\n",
    "\n",
    "\n",
    "'''\n",
    "If min distance < threshold, merge clusters, otherwise keep create new cluster\n",
    "'''\n",
    "threshold = .000001\n",
    "new_cluster_id = max(df_990['labels'])\n",
    "final_labels = []\n",
    "for i in combined_clusters.index:\n",
    "    if combined_clusters.loc[i, 'min_distance'] < threshold:\n",
    "        final_labels.append(combined_clusters.loc[i, 'labels_990'])\n",
    "    else:\n",
    "        new_cluster_id += 1\n",
    "        final_labels.append(new_cluster_id)\n",
    "combined_clusters['final_labels'] = [int(x) for x in final_labels]\n",
    "combined_clusters['labels_EZ'] = combined_clusters['labels_EZ'].astype('int64')\n",
    "\n",
    "\n",
    "'''\n",
    "Add final_label to df_990EZ dataframe\n",
    "'''\n",
    "df_990EZ = df_990EZ.merge(combined_clusters[['labels_EZ', 'final_labels']], how = 'left', left_on = 'labels', right_on = 'labels_EZ')\n",
    "df_990EZ = df_990EZ.drop(['labels', 'labels_EZ'], axis = 1)\n",
    "df_990EZ = df_990EZ.rename(index = str, columns = {'final_labels': 'labels'})\n",
    "\n",
    "'''\n",
    "Final dataframe with labels\n",
    "'''\n",
    "df_original = df_original.merge(df_990[['EIN', 'labels']], how = 'left', on = 'EIN')\n",
    "df_original = df_original.merge(df_990EZ[['EIN', 'labels']], how = 'left', on = 'EIN')\n",
    "df_original['labels'] = df_original['labels_x'].combine_first(df_original['labels_y'])\n",
    "df_original = df_original.drop(['labels_x', 'labels_y'], axis = 1)\n",
    "df_original['labels'] = df_original['labels'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_original.to_csv('./labels_M7.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaleColumns(df, cols_to_scale, scaler):\n",
    "#     for col in cols_to_scale:\n",
    "#         df[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(df[col])),columns=[col])\n",
    "#     return df\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erinhansen/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/erinhansen/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data for variance visualization (Tableau)\n",
    "'''\n",
    "\n",
    "# df_original = pd.read_csv('./labels_M7.csv', dtype = {'FormType': 'object'})\n",
    "df_final_990 = df_original[df_original['FormType'] == '990']\n",
    "df_final_990 = df_final_990[['EIN', 'GrossReceiptsAmt', 'RevenueAmt', 'TotalNetAssetsFundBalanceGrp/EOYAmt', 'TotalLiabilitiesGrp/EOYAmt', 'labels']]\n",
    "df_final_990.columns = ['EIN', 'Gross Receipts', 'Revenue', 'Fund Balance', 'Liabilities', 'labels']\n",
    "\n",
    "df_final_990EZ = df_original[df_original['FormType'] == '990EZ']\n",
    "df_final_990EZ['TotalLiabilitiesGrp/EOYAmt'] = df_final_990EZ['Form990TotalAssetsGrp/EOYAmt'] - df_final_990EZ['NetAssetsOrFundBalancesGrp/EOYAmt']\n",
    "df_final_990EZ = df_final_990EZ[['EIN', 'GrossReceiptsAmt', 'TotalRevenueAmt', 'NetAssetsOrFundBalancesGrp/EOYAmt', 'TotalLiabilitiesGrp/EOYAmt', 'labels']]\n",
    "df_final_990EZ.columns = ['EIN', 'Gross Receipts', 'Revenue', 'Fund Balance', 'Liabilities', 'labels']\n",
    "\n",
    "df_final = df_final_990.append(df_final_990EZ)\n",
    "df_final = df_final.fillna(0)\n",
    "\n",
    "cols = list(df_final.columns)[1:-1]\n",
    "df_final = scaleColumns(df_final, cols, min_max_scaler)\n",
    "# df_final.to_csv('./var_viz_M7.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate distance from cluster center for each org.\n",
    "'''\n",
    "\n",
    "cluster_means = pd.DataFrame(df_final.groupby(['labels']).mean()).reset_index()\n",
    "cluster_means.drop(['EIN'], inplace=True, axis = 1)\n",
    "cluster_means = cluster_means.values\n",
    "\n",
    "clusters = set(df_final['labels'])\n",
    "names = [\"distance_\" + str(cluster) for cluster in clusters]\n",
    "\n",
    "'''\n",
    "Try Euclidean, cosine, and Mahalanobis\n",
    "'''\n",
    "\n",
    "for i, row in enumerate(df_final.values):\n",
    "    for means in cluster_means:\n",
    "        for cluster in clusters:\n",
    "            if means[0] == cluster: # check for same cluster label\n",
    "                x = row[1:-1].reshape([1,4])\n",
    "                y = means[1:].reshape([1,4])\n",
    "                df_final.loc[i, names[cluster-1]] = (float(cosine_similarity(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.to_csv('./df_final_M7.csv', index = False)\n",
    "# df_final.to_csv('./df_final_M8_cosine2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
